{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff4944f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size before sanitisation, Total:  286\n",
      "Removed, Rows with NA:  0\n",
      "Total removal rows:  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222b87068f814cd592029e0d857b0f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Data Cleansing', style=ButtonStyle()), Button(description='Data sets Creati…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ca3728d7334e3cb885df2170b455db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatLogSlider(value=1.0, description='Learning Rate multiplier', layout=Layout(width='400px'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3760465ba4b64f1591feb191e03a8b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=' Begin Training, then optionally display different outputs / internal data for diag…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unittest.mock import inplace\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "######## Widgets for easy control ##########\n",
    "\n",
    "from IPython.core.display_functions import display\n",
    "import ipywidgets as widget\n",
    "from ipywidgets import HBox, VBox\n",
    "\n",
    "style = {'description_width': '150px',\"button_width\":\"150px\"}\n",
    "layout = {'width': '400px'}\n",
    "status_Widget = widget.HTML(\n",
    "    placeholder='Status:',\n",
    "    value= \" Begin Training, then optionally display different outputs / internal data for diagnoses:       \",\n",
    "    layout=layout\n",
    ")\n",
    "training_rate_set = widget.FloatLogSlider(\n",
    "    value=0.01,\n",
    "    min=0.00,\n",
    "    max=0.99,\n",
    "    step=0.01,\n",
    "    readout=True,\n",
    "    description=\"Learning Rate multiplier\",\n",
    "    layout=layout,\n",
    "    style=style,\n",
    ")\n",
    "weight1_multiplier_slider = widget.FloatLogSlider(\n",
    "    value=1.0,\n",
    "    min=0.01,\n",
    "    max=2.50,\n",
    "    step=0.01,\n",
    "    readout=True,\n",
    "    description=\"Initial Weight1\",\n",
    "    layout=layout,\n",
    "    style=style,\n",
    "    button_style='info',\n",
    "    set=True,\n",
    "    disabled=False,\n",
    ")\n",
    "weight2_multiplier_slider = widget.FloatLogSlider(\n",
    "    value=1.0,\n",
    "    min=0.01,\n",
    "    max=2.50,\n",
    "    step=0.01,\n",
    "    readout=True,\n",
    "    description=\"Initial Weight2 \",\n",
    "    layout=layout,\n",
    "    style=style,\n",
    "    button_style='info',\n",
    "    set=True,\n",
    "    disabled=False,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######## Widgets for easy control ##########\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "data = pd.DataFrame( pd.read_excel('./breast-cancer.xls') )  # Data Import from local/ Drive file\n",
    "original_data = data\n",
    "\n",
    "global predictiontable, weight1, weight2,X,Y\n",
    "learning_rate = 0.01\n",
    "error = []\n",
    "Log = widget.Output()\n",
    "\n",
    "################# Data sanitisation #################\n",
    "try: \n",
    "    total_rows = len(data)\n",
    "    print(\"Data size before sanitisation, Total: \", total_rows)\n",
    "    data.dropna(inplace=True) # Drops all NA cells by row and saves it back to source data\n",
    "    print(\"Removed, Rows with NA: \", total_rows - len(data))\n",
    "except:\n",
    "    status_Widget.value += \"--------Failed to remove Null filled rows--------\\n\"\n",
    "\n",
    "def data_cleancing(b):  \n",
    "    status_Widget.value += '--------Began Data_Cleaning to format Data incoming--------\\n' \n",
    "    \n",
    "    global data,numeric_Translation_Menopause,numeric_Translation_NodeCaps,numeric_Translation_Breast,numeric_Translation_irradiat,numeric_Translation_Class\n",
    "    try: \n",
    "\n",
    "        for x in data.index:\n",
    "            if re.search( r\"^[0-9]{1,2}-[0-9]{1,2}$\",  str(data.loc[x, \"age\"]) ) is None and not ( re.search( r\"^[0-9]{1,2}$\",  str(data.loc[x, \"age\"])is None) ): #Using RegEx to confirm age pattern is not \"XX-XX\" / \"X-XX\" and not \"XX\"\n",
    "                data.drop(index=x, inplace=True)\n",
    "            elif re.search(r\"^(ge40)$|^(premeno)$|^(lt40)$\", str(data.loc[x, \"menopause\"])) is None:  #Using RegEx to confirm menopause name is only 1 of three\n",
    "                data.drop(index=x, inplace=True)\n",
    "            elif re.search(r\"^[0-9]{1,2}-[0-9]{1,2}$\", str(data.loc[x, \"tumor-size\"]) ) is None:  #Using RegEx to confirm tumor size is formated correctly\n",
    "                data.drop(index=x, inplace=True)\n",
    "            elif re.search(r\"^[0-9]{1,2}-[0-9]{1,2}$\", str(data.loc[x, \"inv-nodes\"])) is None: #Using RegEx to confirm node-caps is only yes or no Upper or lower case\n",
    "                data.drop(index=x, inplace=True)\n",
    "            elif re.match(r'^([Yy][eE][Ss]|[Nn][oO])$', str(data.loc[x, \"node-caps\"])) is None:  #Using RegEx to confirm inv-nodes count is a number range\n",
    "                data.drop(index=x, inplace=True)\n",
    "            elif re.search(r\"^1$|^2$|^3$\", str(data.loc[x, \"deg-malig\"])) is None:  #Using RegEx to confirm inv-nodes count is a number range\n",
    "                data.drop(index=x, inplace=True)\n",
    "            elif re.search(r\"^([Ll][eE][fF][tT]|[Rr][Ii][Gg][hH][tT])$\", str(data.loc[x, \"breast\"])) is None:  #Using RegEx to confirm inv-nodes count is a number range\n",
    "                data.drop(index=x)\n",
    "            elif re.search(r\"^(left_up|left_low|central|right_up|right_low)$\", str(data.loc[x, \"breast-quad\"]), re.IGNORECASE) is None:\n",
    "                data.drop(index=x)#Using RegEx to confirm inv-nodes count is a number range\n",
    "\n",
    "            #Force only standard answer for this query, Yes / Recurence will = Recurrence-event, anything with no / non = Non-recurrence-event\n",
    "            elif re.search(r\"(non|no|recurrence|Yes)\", str(data.loc[x, \"Class\"]), re.IGNORECASE) is None:\n",
    "                data.loc[x, \"Class\"] = \"Non-recurrence-event\"\n",
    "            if re.search(r\"(non|no)\", str(data.loc[x, \"Class\"]), re.IGNORECASE) :\n",
    "                data.loc[x, \"Class\"] = \"Non-recurrence-event\"\n",
    "            else:\n",
    "                data.loc[x, \"Class\"] = \"Recurrence-event\"\n",
    "                data.drop(index=x)\n",
    "        range_median('age')\n",
    "        range_median('tumor-size')\n",
    "        range_median('inv-nodes')\n",
    "        numeric_Translation_Menopause = uniques_translator('menopause', False)\n",
    "        numeric_Translation_NodeCaps = uniques_translator('node-caps', False)\n",
    "        numeric_Translation_Breast = uniques_translator('breast', False)\n",
    "        numeric_Translation_irradiat = uniques_translator('irradiat', False)\n",
    "        numeric_Translation_Class = uniques_translator('Class', False)\n",
    "        ##  Dictionary of the change to revert back later    ##\n",
    "\n",
    "        ## Translating all string columns to int equivilant  ##\n",
    "        uniques_translator('menopause', True)\n",
    "        uniques_translator('node-caps', True)\n",
    "        uniques_translator('breast-quad', True)\n",
    "        uniques_translator('breast', True)\n",
    "        uniques_translator('irradiat', True)\n",
    "        uniques_translator('Class', True)\n",
    "\n",
    "        ## Translating all string columns to int equivilant  ##\n",
    "        \n",
    "        \n",
    "        ## Range medium finder for all non int only columns\n",
    "\n",
    "        data = data[['age', 'menopause', 'tumor-size', 'inv-nodes','node-caps','deg-malig','breast','breast-quad','irradiat','Class']].apply(lambda e: (e - e.min()) / (e.max() - e.min()))\n",
    "        status_Widget.value += '--------Completed without issue--------\\n'\n",
    "    except:\n",
    "        status_Widget.value += '--------Failed to complete database formatting--------\\n'\n",
    "\n",
    "data_cleancing        \n",
    "data.reset_index(drop=True, inplace=True)  # Re indexes entire dataframe to fix deleted rows\n",
    "print(\"Total removal rows: \" , total_rows - len(data))\n",
    "################# Data sanitisation #################\n",
    "\n",
    "################# Data Formating #################\n",
    "def range_median(column):\n",
    "    status_Widget.value = 'Range Medium Run on Column: ' + column\n",
    "    main_array = []\n",
    "    for y in data.index:\n",
    "        value = str(data.loc[y, column])\n",
    "        if re.search(r\"^[0-9]{1,2}-[0-9]{1,2}$\", str(value)) is not None:\n",
    "            array = np.array(re.findall(r\"[0-9]{1,2}\", value), dtype=int)\n",
    "            main_array.append(np.median(array))\n",
    "\n",
    "        elif  re.search( r\"^[0-9]{1,2}$\",  value)is not None:\n",
    "            array = np.array(re.findall(r\"[0-9]{1,2}\", value), dtype=int)\n",
    "            main_array.append(np.median(array))\n",
    "    data[str(column)] = main_array\n",
    "    return main_array\n",
    "\n",
    "\n",
    "def uniques_translator(column, inpalce_trigger):\n",
    "    status_Widget.value = '--------Uniques_Translation Run on Column: ' + column + \" --------\\n\"\n",
    "    column_uniques = np.array(pd.unique(data[column]))\n",
    "    translation_dictionary = {}\n",
    "    for x in range(column_uniques.size):\n",
    "        translation_dictionary.update({x : column_uniques[x]})\n",
    "    if inpalce_trigger == True:\n",
    "        data[str(column)] = data[[str(column)]].replace(column_uniques, translation_dictionary.keys())\n",
    "        return data[[str(column)]]\n",
    "    else:\n",
    "        return data[[str(column)]].replace(column_uniques, translation_dictionary) , translation_dictionary\n",
    "\n",
    "##  Dictionary of the change to revert back later    ##\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################# Data Formating #################\n",
    "\n",
    "################# Training Data Masking #################\n",
    "\n",
    "def data_sets_creation(b):\n",
    "    status_Widget.value = \"--------Creating Data sets--------\\n\"\n",
    "    global Training_Data,Testing_Data,X,Y,targets\n",
    "    try:\n",
    "\n",
    "\n",
    "        training_data_per =  90/100.0\n",
    "\n",
    "        data['train'] = np.random.rand(len(data)) < training_data_per # Creates random array for each row  of Data, true or false using the fraction\n",
    "        Training_Data = data[data.train == 1] # Appends train Data with the array for each row, effectively showing which row at random will be removed\n",
    "\n",
    "        Training_Data = Training_Data.drop('train', axis=1).sample(frac=1)\n",
    "        ################# Training Data Masking #################\n",
    "\n",
    "        ################# Testing Data Seperation / Masking #################\n",
    "        Testing_Data = data[data.train == 0]\n",
    "        Testing_Data.drop('train', axis=1, inplace=True)\n",
    "\n",
    "        Training_Data = data[data.train == 1]\n",
    "        Training_Data.drop('train', axis=1, inplace=True)\n",
    "        #Using X to remove Class colum as Y will be the opposite, As it is the diagnoses column\n",
    "        #Y = 0  1\n",
    "        #    1  0\n",
    "        #    1  0\n",
    "        #    1  0\n",
    "        #    0  1\n",
    "        # == [0,0,0,1.....]\n",
    "        \n",
    "        X = Training_Data.drop('Class', axis=1).to_numpy(dtype=float)\n",
    "\n",
    "        targets = [[1,0],[0,1]]\n",
    "        Y = np.array([targets[int(z[0])]  for z in Training_Data.values[:,8:9]])\n",
    "        status_Widget.value += '--------Completed without issue--------\\n'\n",
    "    except IndexError:\n",
    "        status_Widget.value += '--------Training_data_sets Creation failed IndexError--------\\n' \n",
    "    except ValueError:\n",
    "        status_Widget.value += '--------Training_data_sets Creation failed ValueError--------\\n' \n",
    "    except TypeError:\n",
    "        status_Widget.value += '--------Training_data_sets Creation failed TypeError--------\\n' \n",
    "################# Testing Data Seperation / Masking #################\n",
    "\n",
    "################# Backpropagating data creation #################\n",
    "\n",
    "weight1_multiplier = 1  # User controllable variables\n",
    "weight2_multiplier = 1\n",
    "\n",
    "def weight_creation(b):\n",
    "    status_Widget.value += '     Began creation of propegation weights'\n",
    "    global weight1,weight2\n",
    "\n",
    "    try:\n",
    "        NumberInput = len(X[0])\n",
    "        Hidden_layer_Rows = 9\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "        weight1 = ( rng.uniform(-1, 1, (NumberInput, Hidden_layer_Rows)) - 1 ) * weight1_multiplier\n",
    "        NumberOutputs = len(Y[0])\n",
    "        weight2 = ( np.random.random((Hidden_layer_Rows, NumberOutputs)) - 1 ) * weight2_multiplier\n",
    "\n",
    "        #Weight1 is [9 Columns]         and  [X length Rows]\n",
    "        #Weight2 is [Y length Columns]  and  [ 4 Rows]\n",
    "        # For Matrix Multiplication operation later\n",
    "    except:\n",
    "        status_Widget.value += '--------Failed to create propegation Weights--------\\n'\n",
    "\n",
    "\n",
    "################# Backpropagating data creation #################\n",
    "\n",
    "\n",
    "def train(b):\n",
    "    global weight1, weight2,error                     #####Currently X is not being see\n",
    "    for epoch in range(5000):\n",
    "        # X shape = 166, 9\n",
    "        # weight1 = 9,9\n",
    "        # weight2 = 9,2\n",
    "\n",
    "        l1 = 1/(1 + np.exp(-(X @ weight1))) # shape (166, 9)\n",
    "\n",
    "        l2 = 1/(1 + np.exp(-(l1 @ weight2))) # (166, 2)\n",
    "        er = (abs(Y - l2)).mean()\n",
    "        error.append(er)\n",
    "\n",
    "        l2_delta = (Y - l2)*(l2 * (1-l2)) \n",
    "        weight2 += l1.T.dot(l2_delta) * learning_rate\n",
    "\n",
    "        l1_delta = l2_delta.dot(weight2.T) * (l1 * (1-l1))\n",
    "        weight1 += X.T.dot(l1_delta) * learning_rate\n",
    "        \n",
    "\n",
    "    #print(er)\n",
    "#print(\"error\" , error[-1])\n",
    "\n",
    "\n",
    "\n",
    "# taken from> https://gist.github.com/craffel/2d727968c3aaebd10359\n",
    "def draw_neural_net(ax, left, right, bottom, top, layer_sizes):\n",
    "    '''\n",
    "    Draw a neural network cartoon using matplotilb.\n",
    "\n",
    "    :usage:\n",
    "        >>> fig = plt.figure(figsize=(12, 12))\n",
    "        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])\n",
    "\n",
    "    :parameters:\n",
    "        - ax : matplotlib.axes.AxesSubplot\n",
    "            The axes on which to plot the cartoon (get e.g. by plt.gca())\n",
    "        - left : float\n",
    "            The center of the leftmost node(s) will be placed here\n",
    "        - right : float\n",
    "            The center of the rightmost node(s) will be placed here\n",
    "        - bottom : float\n",
    "            The center of the bottommost node(s) will be placed here\n",
    "        - top : float\n",
    "            The center of the topmost node(s) will be placed here\n",
    "        - layer_sizes : list of int\n",
    "            List of layer sizes, including input and output dimensionality\n",
    "    '''\n",
    "    n_layers = len(layer_sizes)\n",
    "    v_spacing = (top - bottom)/float(max(layer_sizes))\n",
    "    h_spacing = (right - left)/float(len(layer_sizes) - 1)\n",
    "    # Nodes\n",
    "    for n, layer_size in enumerate(layer_sizes):\n",
    "        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.\n",
    "        for m in range(layer_size):\n",
    "            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,\n",
    "                                color='w', ec='k', zorder=4)\n",
    "            ax.add_artist(circle)\n",
    "    # Edges\n",
    "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
    "        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
    "        for m in range(layer_size_a):\n",
    "            for o in range(layer_size_b):\n",
    "                line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],\n",
    "                                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')\n",
    "                ax.add_artist(line)\n",
    "\n",
    "#fig = plt.figure(figsize=(5, 5))\n",
    "#ax = fig.gca()\n",
    "#ax.axis('off')\n",
    "#draw_neural_net(ax, .1, .9, .1, .9, [9, 2, 1])\n",
    "\n",
    "def testing(b):\n",
    "    status_Widget.value += '--------Testing Begun--------\\n'\n",
    "    global predictiontable\n",
    "    try: \n",
    "\n",
    "        X_testing = pd.DataFrame(Testing_Data.drop('Class', axis=1).values.astype(float))   # shape (length, 9)\n",
    "\n",
    "        Y_Testing = np.array([targets[int(r[0])]  for r in Testing_Data.values])\n",
    "\n",
    "        l1 = 1/(1 + np.exp(-(X_testing @ weight1)))\n",
    "        l2 = 1/(1 + np.exp(-(l1 @ weight2)))\n",
    "        y_prediction = np.argmax(l2 , axis = 1)\n",
    "\n",
    "        #print(Y_Prediction)\n",
    "        resolution = y_prediction == np.argmax(Testing_Data['Class'], axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "        correct = np.sum(resolution)/len(resolution)\n",
    "        predictiontable = Testing_Data['Class'].replace([0,1], ['recurrence-events', 'no-recurrence-events']).to_frame().reset_index()\n",
    "        predictiontable['prediction'] = pd.Series(resolution).replace([False,True], ['recurrence-events', 'no-recurrence-events'])\n",
    "        predictiontable['Check'] = (pd.Series(y_prediction) != np.argmax(Y_Testing, axis=1))\n",
    "        predictiontable['Raw_value_l2'] = y_prediction\n",
    "        predictiontable['original_Raw_value'] = Testing_Data['Class'].reset_index().drop('index', axis=1)\n",
    "        #print(l2[0])\n",
    "        \n",
    "        print('Correct:',sum(resolution),'/',len(resolution), ':', (correct*100),'%')\n",
    "        return True\n",
    "    \n",
    "    except:  \n",
    "        return False\n",
    "\n",
    "def draw_error_graph():\n",
    "    global status_Widget\n",
    "    if error :\n",
    "        plt.plot(error)\n",
    "    else:\n",
    "        status_Widget.value += \"--------No Data to Plot--------\\n\"\n",
    "Incoming_Sanatisation = widget.Button(\n",
    "    set=False,\n",
    "    description=\"Data Cleansing\",\n",
    "    disable=False,\n",
    "    style=style\n",
    ")\n",
    "Data_sets_Creation = widget.Button(\n",
    "    set=False,\n",
    "    description=\"Data sets Creation\",\n",
    "    disable=False,\n",
    "    style=style\n",
    ")\n",
    "Weight_Generator = widget.Button(\n",
    "    set=False,\n",
    "    description=\"Create Weights\",\n",
    "    disable=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "Training_trigger_button = widget.Button(\n",
    "    set=False,\n",
    "    description=\"Begin Trianing\",\n",
    "    disable=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "toggle_learning_graph_error = widget.Button(\n",
    "    button_style='info',\n",
    "    description=\"Error Plot Curve\",\n",
    "    disable=False,\n",
    "    style=style,\n",
    "    icon='question'\n",
    ")\n",
    "\n",
    "def observer(change):\n",
    "    widget_Name = change[\"owner\"].description \n",
    "\n",
    "    try:\n",
    "        if widget_Name == \"weight1_multiplier_slider\":\n",
    "            weight1_multiplier = weight1_multiplier_slider.value\n",
    "        elif widget_Name == \"weight2_multiplier_slider\":\n",
    "            weight2_multiplier = weight2_multiplier_slider.value\n",
    "        elif widget_Name == \"training_rate_set\":\n",
    "            learning_rate = training_rate_set\n",
    "\n",
    "    except:\n",
    "        status_Widget.value += \"--------Failed to follow through with user input--------\\n\"\n",
    "\n",
    "\n",
    "Incoming_Sanatisation.on_click(data_cleancing)\n",
    "Data_sets_Creation.on_click(data_sets_creation)\n",
    "Training_trigger_button.on_click(train)\n",
    "Weight_Generator.on_click(weight_creation)\n",
    "weight1_multiplier_slider.observe(observer, names='value')\n",
    "weight2_multiplier_slider.observe(observer, names='value')\n",
    "training_rate_set.observe(observer, names='value')\n",
    "display(HBox([Incoming_Sanatisation, Data_sets_Creation, Training_trigger_button,  toggle_learning_graph_error]))\n",
    "display(HBox([training_rate_set,    weight2_multiplier_slider,  weight1_multiplier_slider ]), HBox([status_Widget   ]))\n",
    "data_cleancing(1)\n",
    "data_sets_creation(1)\n",
    "\n",
    "#weight_creation(1)\n",
    "#train(1)\n",
    "#draw_error_graph()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
